<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Brodie Gaslam" />


<title>unitizeR - Test Details</title>






<link href="data:text/css;charset=utf-8,%0Abody%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E5%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0A%0Apadding%3A%204px%3B%0Awidth%3A%20100%25%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%201em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23eee%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%3B%0Apadding%3A%2010px%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23eee%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%2C%20h1%20%3E%20code%2C%20h2%20%3E%20code%2C%20h3%20%3E%20code%2C%0Ah4%20%3E%20code%2C%20h5%20%3E%20code%2C%20h6%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0Aline%2Dheight%3A%201%3B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Apadding%2Dbottom%3A%203px%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0Aborder%2Dbottom%3A%201px%20solid%20%23999%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23999%3B%0Apadding%2Dtop%3A%205px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Apadding%2Dtop%3A%205px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0A%0Acolor%3A%20%23777%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah4%2Eauthor%2C%20h4%2Edate%20%7Bdisplay%3A%20none%3B%7D%0Ah5%2C%20h6%20%7B%0A%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%232255dd%3B%0Afont%2Dweight%3A%20bold%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">unitizeR - Test Details</h1>
<h4 class="author"><em>Brodie Gaslam</em></h4>


<div id="TOC">
<ul>
<li><a href="#understanding-tests">Understanding Tests</a><ul>
<li><a href="#test-outcomes">Test Outcomes</a></li>
<li><a href="#what-constitutes-a-test">What Constitutes a Test?</a></li>
<li><a href="#unitizer-test-components"><code>unitizer</code> Test Components</a></li>
</ul></li>
<li><a href="#sections">Sections</a><ul>
<li><a href="#untizer_sect"><code>untizer_sect</code></a></li>
<li><a href="#controlling-test-comparison">Controlling Test Comparison</a></li>
</ul></li>
<li><a href="#other-details">Other Details</a><ul>
<li><a href="#matching-tests">Matching Tests</a></li>
<li><a href="#commenting-tests">Commenting Tests</a></li>
<li><a href="#options-and-streams">Options and Streams</a></li>
</ul></li>
</ul>
</div>

<div id="understanding-tests" class="section level2">
<h2>Understanding Tests</h2>
<div id="test-outcomes" class="section level3">
<h3>Test Outcomes</h3>
<p>When <code>unitize</code> is run with a test file against an existing <code>unitizer</code> store, each test in the file is matched and compared to the corresponding test in the store. Here is a comprehensive list of possible outcomes:</p>
<ul>
<li><strong>New</strong>: a test present in the file is not in the store and needs to be reviewed to confirm it is correct</li>
<li><strong>Passed</strong>: the test matched the reference test in the store and need not be reviewed</li>
<li><strong>Failed</strong>: the evaluation of the test from the file differs from the one produced by same expression in the store</li>
<li><strong>Deleted/Removed</strong>: a test present in the <code>unitizer</code> store no longer exists in the test file so you will be prompted to remove it from the store</li>
<li><strong>Corrupted/Error</strong>: an error occurred while attempting to compare the file and store tests; this should occur very rarely and is likely the result of using a custom comparison function to compare the tests (see <a href="#controlling-test-comparison"><code>unitizer_sect</code></a> for more details on custom comparison functions). Because the comparison function itself failed, <code>unitizer</code> has no way of knowing whether the test passed or failed; you can think of it as an <code>NA</code> outcome.</li>
</ul>
<p>When reviewing tests, <code>unitizer</code> will group tests by test type, so you will review all new tests in one go, then the failed tests, and so on. As a result, the order that you review tests may not be the same as the order they appear in in the test file.</p>
</div>
<div id="what-constitutes-a-test" class="section level3">
<h3>What Constitutes a Test?</h3>
<p>As noted previously simple assignments are not considered tests. They are stored in the <code>unitizer</code> store, but you are not asked to review them, and their values are not compared to existing reference values prior to storage. The implicit assumption is that if there is an assignment the intent is to use the resulting object in some later test at which point any issues will crop up. Skipping assignment review saves some unnecessary user interaction.</p>
<p>You can force assignments to become tests by wrapping them in parentheses:</p>
<pre><code>a &lt;- my_fun(25)     # this is not a test
(a &lt;- my_fun(42))   # this is a test</code></pre>
<p>The actual rule <code>unitizer</code> uses to decide whether an expression is a test or not is whether it returns invisibly. Wrapping parentheses around an expression that returns invisibly makes it visible, which is why assignments in parentheses become tests. Conversely, you can wrap an expression in <code>invisible(...)</code> to prevent it from being treated as a test.</p>
</div>
<div id="unitizer-test-components" class="section level3">
<h3><code>unitizer</code> Test Components</h3>
<p>The following aspects of a unitizer tests are recorded for future comparison:</p>
<ul>
<li>Value</li>
<li>Conditions</li>
<li>Screen (stdout) output</li>
<li>Message (stderr) output</li>
<li>Whether the expression issued an “abort” <code>invokeRestart</code> (e.g. was <code>stop</code> called in the expression)</li>
</ul>
<p>Currently only the first two elements are actually compared when determining whether a test passes or fails. These two should capture almost all you would care about from a unit test perspective.</p>
<p>Screen output is omitted from comparison because it can be caused to vary substantially by factors unrelated to source code changes (e.g. console display width). Screen output will also seem identical to the value as most of the time screen output is just the result of printing the return value of an expression. This will not be the case if the expression itself prints to <code>stdout</code> explicitly, or if the function returns invisibly.</p>
<p>Message output is omitted because all typical mechanisms for producing <code>stderr</code> output also produce conditions with messages embedded, so it is usually superfluous to compare them. One exception would be if an expression <code>cat</code>ed to <code>stderr</code> directly.</p>
<p>The “abort” <code>invokeRestart</code> is omitted because it generally is implied by the presence of an error condition and actively monitoring it clutters the diagnostic messaging produced by <code>unitizer</code>. It exists because it is possible to signal a “stop” condition without actually triggering the “abort” restart so in some cases it could come in handy.</p>
<p>While we omit the last three components from comparison, this is just default behavior. You can change this by using the <code>compare</code> argument for <a href="#controlling-test-comparison"><code>unitizer_sect</code></a>.</p>
</div>
</div>
<div id="sections" class="section level2">
<h2>Sections</h2>
<div id="untizer_sect" class="section level3">
<h3><code>untizer_sect</code></h3>
<p>Often it is useful to group tests in sections for the sake of documentation and clarity. Here is a slghtly modified version of the original demo file with sections:</p>
<pre><code>unitizer_sect(&quot;Basic Tests&quot;, {
  library(unitizer.fastlm)
  x &lt;- 1:10
  y &lt;- x ^ 3
  res &lt;- fastlm(x, y)

  get_slope(res)
})

unitizer_sect(&quot;Advanced Tests&quot;, {
  2 * get_slope(res) + get_intercept(res)
  get_rsq(res)
})</code></pre>
<p>Now re-running <code>unitizer</code> segments everything by section (note, first few lines are set-up):</p>
<pre><code>(.unitizer.fastlm &lt;- copy_fastlm_to_tmpdir())
update_fastlm(.unitizer.fastlm, version=&quot;0.1.2&quot;)
devtools::install(.unitizer.fastlm, quiet=TRUE)
unitize(file.path(.unitizer.fastlm, &quot;tests&quot;, &quot;unitizer&quot;, &quot;unitizer.fastlm.R&quot;))

+------------------------------------------------------------------------------+
| unitizer for: tests/unitizer/unitizer.fastlm.R                               |
+------------------------------------------------------------------------------+

                    Pass Fail  New
 1.    Basic Tests     -    -    1
 2. Advanced Tests     -    -    2
..................................
                       -    -    3
</code></pre>
<p>If there are tests that require reviewing, each section will be reviewed in turn.</p>
<p>Note that <code>unitizer_sect</code> does not create separate evaluation environments for each section. Any created object will be available to all lexically subsequent tests, regardless of whether they are in the same section or not.</p>
<p>It is possible to have nested sections, though at this point in time <code>unitizer</code> only explicitly reports information at the outermost section level.</p>
</div>
<div id="controlling-test-comparison" class="section level3">
<h3>Controlling Test Comparison</h3>
<p>By default tested components (values and conditions) are compared with <code>all.eq</code>, a wrapper around <code>all.equal</code> that returns FALSE on inequality instead of a character description of the inequality. If you want to override the function used for value comparisons it is as simple as creating a new section for the tests you want to compare differently and use the <code>compare</code> argument:</p>
<pre><code>unitizer_sect(&quot;Accessor Functions&quot;, compare=identical,
  {
    get_slope(res)
    get_rsq(res)
    get_intercept(res)
} )</code></pre>
<p>The values produced by these three tests will be compared using <code>identical</code> instead of <code>all.eq</code>. If you want to modify how other components of the test are compared, then you can pass a <code>unitizerItemTestsFuns</code> object as the value to the <code>compare</code> argument instead of a function:</p>
<pre><code>unitizer_sect(&quot;Accessor Functions&quot;,
  compare=unitizerItemTestsFuns(
    value=identical,
    output=all.equal,
    message=identical
  ),
  {
    get_slope(res)
    get_rsq(res)
    get_intercept(res)
} )</code></pre>
<p>This will cause the value of tests to be compared with <code>identical</code>, the screen output with <code>all.equal</code>, and messages (stderr) with <code>identical</code>.</p>
<p>If you want to change the comparison function for conditions, keep in mind that what you are comparing are <code>conditionList</code> objects so this is not straightforward (see <code>getMethod(&quot;all.equal&quot;, &quot;conditionList&quot;)</code>). In the future we might expose a better interface for custom comparison functions for conditions (see issue #32).</p>
<p>If you need to have different comparison functions within a section, use nested sections. While <code>unitizer</code> will only report the outermost section metrics in top-level summaries, the specified comparison functions will be used for each nested section.</p>
</div>
</div>
<div id="other-details" class="section level2">
<h2>Other Details</h2>
<div id="matching-tests" class="section level3">
<h3>Matching Tests</h3>
<p>Whenever you re-run <code>unitize</code> on a file that has already been <code>unitize</code>d, <code>unitizer</code> matches the expressions in that file to those stored in the corresponding <code>unitizer</code> store. <code>unitizer</code> matches only on the deparsed expression, and does not care at all where in the file the expression occurs. If multiple identical expressions exist in a file they will be matched in the order they show up.</p>
<p>The <code>unitizer_sect</code> in which a test was when it was first <code>unitize</code>d has no bearing whatsoever on matching a new test to a reference test. For example, if a particular test was in “Section A” when it was first <code>unitize</code>d, but in the current version of the test file it is in “Section X”, that test will be matched to the current one in “Section X”.</p>
</div>
<div id="commenting-tests" class="section level3">
<h3>Commenting Tests</h3>
<p><code>unitizer</code> parses the comments in the test files and attaches them to the test that they document. Comments are attached to tests if they are on the same line as the test, or in the lines between a test and the previous test. Comments are displayed with the test expression during the interactive review mode.</p>
</div>
<div id="options-and-streams" class="section level3">
<h3>Options and Streams</h3>
<p>In order to properly capture output, <code>unitizer</code> will modify streams and options. In particular, it will do the following:</p>
<ul>
<li>temporarily set <code>options(warn=1L)</code> during expression evaluation</li>
<li>temporarily set <code>options(error=NULL)</code> during expression evaluation</li>
<li>use <code>sink()</code> to capture any output to <code>stdout</code></li>
<li>use <code>sink(type=&quot;message&quot;)</code> to capture output to <code>stderr</code></li>
</ul>
<p>This should all be transparent to the user, unless the user is also attempting to modify these settings in the test expressions. The problematic interaction are around the <code>options</code> function. If the user sets <code>options(warn=1)</code> with the hopes that setting will persist beyond the execution of the test scripts, that will not happen. If the user sets <code>options(error=recover)</code> or some such in a test expression, and that expression throws an error, you will be thrown into recovery mode with no visibility of <code>stderr</code> or <code>stdout</code>, which will make for pretty challenging debugging. Similarly, <code>unitize</code>ing <code>debug</code>ged functions, or interactive functions, is unlikely to work well.</p>
<p>If <code>unitize</code> is run with <code>sdtderr</code> or <code>stdout</code> sunk, then it will subvert the sink during test evaluation and reset it to the same sinks on exit. If a test expression sinks either stream, <code>unitizer</code> will stop capturing output from that point on until the end of the test file. At that point, it will attempt to reset the sinks to what they were when <code>unitizer</code> started. Sometimes this is not actually possible. If such a situation occurs, <code>unitizer</code> will release all sinks to try to avoid a situation where control is returned to the user with output streams still captured.</p>
<p>To reduce the odds of storing massive and mostly useless <code>stdout</code>, <code>unitize</code> limits how much output is stored by default. If you exceed the limit you will be warned. You may modify this setting with <code>options(&quot;unitizer.max.capture.chars&quot;)</code>.</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
